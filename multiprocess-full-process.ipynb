{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Commonly Used Words by Each Author - Parallelize Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start time calculating\n",
    "start= timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiprocess funaction for dataframe processing\n",
    "from multiprocess import Pool, TimeoutError, cpu_count\n",
    "\n",
    "def parallelize_dataframe(df, func, n_cores=4):\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "### OPERATION 1 ###\n",
    "\n",
    "#laod data\n",
    "df = pd.read_csv(\"D:/UOB Master BDSA/BDSA606 High Performance Computing/Project/quotes.csv\")\n",
    "#df = pd.read_csv('/dbfs/FileStore/tables/quotes.csv')\n",
    "\n",
    "#view sample data\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(df):\n",
    "    \n",
    "### OPERATION 2 ####\n",
    "\n",
    "  #dropping column category as not required for this problem\n",
    "  df=df.drop(columns=['category'])\n",
    "  #view sample data\n",
    "  #df.head(3)\n",
    "\n",
    "  #reiew dataset shape\n",
    "  #print(\"Dataset shape is:\",df.shape)\n",
    "  #check missing values\n",
    "  #print(\"\\nThere are missing values under columns:\\n\",df.isnull().sum())\n",
    "\n",
    "  #DROP rows of missing values\n",
    "  df=df.dropna()\n",
    "  #check missing values\n",
    "  #print(\"\\nMissing values dropped, now there are no missing values:\\n\",df.isnull().sum())\n",
    "  #reiew dataset shape\n",
    "  #print(\"\\nDataset shape after dropping missing values:\",df.shape)\n",
    "\n",
    "  #COMBINE quotes for each author\n",
    "  df=df.groupby(['author'])['quote'].apply(','.join).reset_index()\n",
    "  #reiew dataset shape\n",
    "  #print(\"\\nDataset shape after joining quotes for each author:\",df.shape)\n",
    "  #check missing values\n",
    "  #print(\"\\nThere are missing values after joining quotes:\\n\",df.isnull().sum())\n",
    "  #view combined quotes\n",
    "  #df.head(3)\n",
    "\n",
    "### OPERATION 3 ####\n",
    "\n",
    "  #replace spaces and special chars with dot\n",
    "  df.replace(\"'\",'\"',inplace=True)\n",
    "  df.quote = df.quote.str.replace(' ', '.')\n",
    "  df.quote = df.quote.str.replace(',', '.')\n",
    "  df.quote = df.quote.str.replace('-', '.')\n",
    "  df.quote = df.quote.str.replace('_', '.')\n",
    "  df.quote = df.quote.str.replace('#', '.')\n",
    "  df.quote = df.quote.str.replace('$', '.')\n",
    "  df.quote = df.quote.str.replace('/', '.')\n",
    "  df.quote = df.quote.str.replace('\\'', '.')\n",
    "  df.quote = df.quote.str.replace('&', '.')\n",
    "  df.quote = df.quote.str.replace('\"', '.')\n",
    "  df.quote = df.quote.str.replace('@', '.')\n",
    "  df.quote = df.quote.str.replace(':', '.')\n",
    "  df.quote = df.quote.str.replace('â€™', '.')\n",
    "  #view updates values\n",
    "  #df.head(10)\n",
    "\n",
    "### OPERATION 4 ####\n",
    "\n",
    "  #split quote into words \n",
    "  from itertools import chain\n",
    "  cols = df.columns.difference(['quote'])\n",
    "  words = df['quote'].str.split('.')\n",
    "  df =  (df.loc[df.index.repeat(words.str.len()), cols]\n",
    "         .assign(words=list(chain.from_iterable(words.tolist()))))\n",
    "\n",
    "  #reiew dataset shape\n",
    "  #print(\"Dataset shape after splitting quotes into words is:\",df.shape)\n",
    "\n",
    "  #check missing values\n",
    "  #print(\"\\nThere are missing values under columns:\\n\",df.isnull().sum())\n",
    "  #df.head(3)\n",
    "\n",
    "### OPERATION 5 ####\n",
    "\n",
    "  #drop words with less than 3 char..and incorrect author name values\n",
    "  df['length'] = df.words.str.len()\n",
    "  df['length2'] = df.author.str.len()\n",
    "  df2 = df[df.length > 4]\n",
    "  df2 = df2[df2.length2 > 4]\n",
    "  df2 = df2[df2.length2 < 30]\n",
    "\n",
    "  #dropping column category as not required for this problem\n",
    "  df2=df2.drop(columns=['length'])\n",
    "  df2=df2.drop(columns=['length2'])\n",
    "\n",
    "  #find count for words\n",
    "  df=df2.groupby(['author', 'words']).size().reset_index(name='counts')\n",
    "\n",
    "  #reiew dataset shape\n",
    "  #print(\"Dataset shape after removing words less than 3 words' charachters and dropping incorrect authros name values and adding words counts column:\",df.shape)\n",
    "\n",
    "  #view updated dataframe\n",
    "  #print(df.head(3))\n",
    "\n",
    "  #count unqiue authors\n",
    "  #print(\"\\nNumber of authors is\",df['author'].count())\n",
    "  #print(\"Number of unqiue authors is\",df['author'].nunique())\n",
    "\n",
    "  #count unqiue words\n",
    "  #print(\"\\nNumber of words is\",df['words'].count())\n",
    "  #print(\"Number of unqiue words is\",df['words'].nunique())\n",
    "\n",
    "  #counts summary\n",
    "  #print(\"\\nNumber of min words count is\",df['counts'].min())\n",
    "  #print(\"Number of max words count is\",df['counts'].max())\n",
    "  #print(\"Mean words count is\",df['counts'].mean())\n",
    "\n",
    "  #drop words repeated less than 3 times\n",
    "  df = df[df.counts > 2]\n",
    "\n",
    "  #counts summary\n",
    "  #print(\"\\nAFTER DROPPING WORDS REPEATED LESS THAN 3 TIMES ONLY - Number of min words count is\",df['counts'].min())\n",
    "  #print(\"AFTER DROPPING WORDS REPEATED LESS THAN 3 TIMES ONLY - Number of max words count is\",df['counts'].max())\n",
    "  #print(\"AFTER DROPPING WORDS REPEATED LESS THAN 3 TIMES ONLY - Mean words count is\",df['counts'].mean())\n",
    "\n",
    "  #count unqiue authors\n",
    "  #print(\"\\nNEW - Number of authors is\",df['author'].count())\n",
    "  #print(\"NEW - Number of unqiue authors is\",df['author'].nunique())\n",
    "\n",
    "  #count unqiue words\n",
    "  #print(\"\\nNEW - Number of words is\",df['words'].count())\n",
    "  #print(\"NEW - Number of unqiue words is\",df['words'].nunique())\n",
    "\n",
    "### OPERATION 6 ####\n",
    "    \n",
    "  #selecting top 5 words for each author\n",
    "  topk=5\n",
    "  df=df.groupby(['author']).apply(lambda x: x.nlargest(topk,['counts'])).reset_index(drop=True)\n",
    "  return df\n",
    "\n",
    "  #reiew dataset shape\n",
    "  #print(\"Dataset shape selecting top 5 words for each author:\",df.shape)\n",
    "\n",
    "  #count unqiue authors\n",
    "  #print(\"\\nNumber of authors is\",df['author'].count())\n",
    "  #print(\"Number of unqiue authors is\",df['author'].nunique())\n",
    "\n",
    "  #count unqiue words\n",
    "  #print(\"\\nNumber of words is\",df['words'].count())\n",
    "  #print(\"Number of unqiue words is\",df['words'].nunique())\n",
    "\n",
    "  #counts summary\n",
    "  #print(\"\\nNumber of min words count is\",df['counts'].min())\n",
    "  #print(\"Number of max words count is\",df['counts'].max())\n",
    "  #print(\"Mean words count is\",df['counts'].mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#RUN FULLY PARALLELIZED PROCESS\n",
    "#selecting top 5 words for each author using multiprocess function\n",
    "df = parallelize_dataframe(df, func)\n",
    "#df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TOTAL TIME OF 6 OPERATIONS ####\n",
    "#end time calculating \n",
    "end = timer()\n",
    "print(\"Time taken:\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Zahra Shuaib ##\n",
    "## zahrashuaib@gmail.com ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
